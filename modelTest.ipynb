{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer, silhouette_score\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 15)\n",
      "(1000, 1)\n",
      "(1000, 15)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "#* I import different version of our dataset so we can see how different transformations effect the models predictions \n",
    "\n",
    "\n",
    "X_train = pd.read_csv(\"X_train_tran.csv\")\n",
    "y_train = pd.read_csv(\"y_train_tran.csv\")\n",
    "y_train = np.ravel(y_train)\n",
    "X_val = pd.read_csv(\"X_val_tran.csv\")\n",
    "y_val = pd.read_csv(\"y_val_tran.csv\")\n",
    "myColumns = X_train.columns\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "\n",
    "X = pd.read_csv(\"X.csv\")\n",
    "X_train_cluster = pd.read_csv(\"X_train_cluster.csv\")\n",
    "X_val_cluster = pd.read_csv(\"X_val_cluster.csv\")\n",
    "X_test_cluster = pd.read_csv(\"X_test_cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'classifier__learning_rate': 0.08, 'classifier__max_depth': 4, 'classifier__n_estimators': 300}\n",
      "Best Score (F1 Macro): 0.7363049516612827\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       796\n",
      "           1       0.72      0.45      0.56       204\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.80      0.70      0.73      1000\n",
      "weighted avg       0.84      0.85      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#! GradientBoostingClassifier\n",
    "\n",
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned']\n",
    "continuous_features_engine = ['BalanceCredit', 'AgeProducts', 'SatisfactionProducts', 'CardProducts', 'TenurePoints']\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary', 'GenderBinary']\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [250, 300, 350],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.08, 0.1],\n",
    "    'classifier__max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), continuous_features_engine),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "gradientBoosting_cls = GradientBoostingClassifier()\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_gbcls = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', gradientBoosting_cls)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_gbcls = GridSearchCV(pipe_gbcls, param_grid, cv=3, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_gbcls.fit(X, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_gbcls.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_gbcls.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_gbcls.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> \n",
    "Ok, so the general approach is to first test a few models that are often recommended for binary classification problems. The based on how they preform un-optimized , i will select that model and try to fine tune it using gridsearchCV\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
    "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
    "Best Parameters: {'classifier__learning_rate': 0.08, 'classifier__max_depth': 4, 'classifier__n_estimators': 300}\n",
    "Best Score (F1 Macro): 0.7363049516612827\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.96      0.91       796\n",
    "           1       0.72      0.45      0.56       204\n",
    "\n",
    "    accuracy                           0.85      1000\n",
    "   macro avg       0.80      0.70      0.73      1000\n",
    "weighted avg       0.84      0.85      0.84      1000\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 300}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       796\n",
      "           1       0.71      0.43      0.54       204\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.79      0.69      0.72      1000\n",
      "weighted avg       0.84      0.85      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#! RandomForestClassifier\n",
    "\n",
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned']\n",
    "continuous_features_engine = ['BalanceCredit', 'AgeProducts', 'SatisfactionProducts', 'CardProducts', 'TenurePoints']\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary', 'GenderBinary']\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), continuous_features_engine),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 5, 10],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "\n",
    "# Define the classifier\n",
    "rf_cls = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_rf_cls = Pipeline(steps=[\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', rf_cls)\n",
    "])\n",
    "\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipe_rf_cls, param, cv=5, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Use the best model for prediction\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
    "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
    "Best Parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 300}\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.95      0.91       796\n",
    "           1       0.71      0.43      0.54       204\n",
    "\n",
    "    accuracy                           0.85      1000\n",
    "   macro avg       0.79      0.69      0.72      1000\n",
    "weighted avg       0.84      0.85      0.83      1000\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'classifier__max_depth': 9, 'classifier__n_estimators': 250, 'preprocessor__target__smoothing': 5}\n",
      "Best Score (F1 Macro): 0.725606372969776\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.91       796\n",
      "           1       0.76      0.43      0.55       204\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.70      0.73      1000\n",
      "weighted avg       0.85      0.86      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#! RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessor__target__smoothing': [1.0,2, 5, 7],\n",
    "    'classifier__n_estimators': [250, 300, 350],\n",
    "    'classifier__max_depth': [6,7,8,9]\n",
    "}\n",
    "\n",
    "\n",
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned']\n",
    "continuous_features_engine = ['BalanceCredit', 'AgeProducts', 'SatisfactionProducts', 'CardProducts', 'TenurePoints']\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary', 'GenderBinary']\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "all_features = continuous_features + ordinal_features + cluster_features + continuous_features_engine + categorical_features\n",
    "\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), all_features),   \n",
    "    ])\n",
    "\n",
    "\n",
    "rf_cls = RandomForestClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_rf_cls_target = Pipeline(steps=[\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', rf_cls)\n",
    "])\n",
    "\n",
    "\n",
    "# pipe_target_enc\n",
    "# Create the GridSearchCV object\n",
    "grid_search_rf_target = GridSearchCV(pipe_rf_cls_target, param_grid, cv=3, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "grid_search_rf_target.fit(X, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_rf_target.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_rf_target.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_rf_target.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
    "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
    "Best Parameters: {'classifier__max_depth': 9, 'classifier__n_estimators': 250, 'preprocessor__target__smoothing': 5}\n",
    "Best Score (F1 Macro): 0.725606372969776\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.97      0.91       796\n",
    "           1       0.76      0.43      0.55       204\n",
    "\n",
    "    accuracy                           0.86      1000\n",
    "   macro avg       0.82      0.70      0.73      1000\n",
    "weighted avg       0.85      0.86      0.84      1000\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'max_depth' for estimator Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('target', TargetEncoder(),\n                                                  ['BalanceCredit',\n                                                   'AgeProducts',\n                                                   'SatisfactionProducts',\n                                                   'CardProducts',\n                                                   'TenurePoints']),\n                                                 ('scaler', StandardScaler(),\n                                                  ['CreditScore', 'Age',\n                                                   'Balance', 'NumOfProducts',\n                                                   'EstimatedSalary',\n                                                   'PointsEarned']),\n                                                 ('ordinal', 'passthrough',\n                                                  ['Tenure', 'CardTypeOrd',\n                                                   'NumOfProducts',\n                                                   'NumOfProducts']),\n                                                 ('cluster', 'passthrough',\n                                                  ['ClusterKMeans',\n                                                   'ClusterBGM']),\n                                                 ('categorical', 'passthrough',\n                                                  ['HasCrCard',\n                                                   'IsActiveMember',\n                                                   'GenderBinary',\n                                                   'GenderBinary'])])),\n                ('classifier', LGBMClassifier())]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\sklearn\\pipeline.py\", line 211, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 70, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\sklearn\\base.py\", line 205, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'max_depth' for estimator Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('target', TargetEncoder(),\n                                                  ['BalanceCredit',\n                                                   'AgeProducts',\n                                                   'SatisfactionProducts',\n                                                   'CardProducts',\n                                                   'TenurePoints']),\n                                                 ('scaler', StandardScaler(),\n                                                  ['CreditScore', 'Age',\n                                                   'Balance', 'NumOfProducts',\n                                                   'EstimatedSalary',\n                                                   'PointsEarned']),\n                                                 ('ordinal', 'passthrough',\n                                                  ['Tenure', 'CardTypeOrd',\n                                                   'NumOfProducts',\n                                                   'NumOfProducts']),\n                                                 ('cluster', 'passthrough',\n                                                  ['ClusterKMeans',\n                                                   'ClusterBGM']),\n                                                 ('categorical', 'passthrough',\n                                                  ['HasCrCard',\n                                                   'IsActiveMember',\n                                                   'GenderBinary',\n                                                   'GenderBinary'])])),\n                ('classifier', LGBMClassifier())]). Valid parameters are: ['memory', 'steps', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m grid_search_lgm_cls \u001b[39m=\u001b[39m GridSearchCV(pipe_lgm_cls, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[39m# Fit the GridSearchCV object to the data\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m grid_search_lgm_cls\u001b[39m.\u001b[39;49mfit(X, y_train)\n\u001b[0;32m     46\u001b[0m \u001b[39m# Print the best parameters and best score\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Parameters:\u001b[39m\u001b[39m\"\u001b[39m, grid_search_lgm_cls\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Magnus\\Desktop\\¤New\\newENV\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'max_depth' for estimator Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('target', TargetEncoder(),\n                                                  ['BalanceCredit',\n                                                   'AgeProducts',\n                                                   'SatisfactionProducts',\n                                                   'CardProducts',\n                                                   'TenurePoints']),\n                                                 ('scaler', StandardScaler(),\n                                                  ['CreditScore', 'Age',\n                                                   'Balance', 'NumOfProducts',\n                                                   'EstimatedSalary',\n                                                   'PointsEarned']),\n                                                 ('ordinal', 'passthrough',\n                                                  ['Tenure', 'CardTypeOrd',\n                                                   'NumOfProducts',\n                                                   'NumOfProducts']),\n                                                 ('cluster', 'passthrough',\n                                                  ['ClusterKMeans',\n                                                   'ClusterBGM']),\n                                                 ('categorical', 'passthrough',\n                                                  ['HasCrCard',\n                                                   'IsActiveMember',\n                                                   'GenderBinary',\n                                                   'GenderBinary'])])),\n                ('classifier', LGBMClassifier())]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "#\n",
    "#! LGBMClassifier\n",
    "\n",
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned']\n",
    "continuous_features_engine = ['BalanceCredit', 'AgeProducts', 'SatisfactionProducts', 'CardProducts', 'TenurePoints']\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary', 'GenderBinary']\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), continuous_features_engine),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__num_leaves': [10, 20, 30],\n",
    "    'classifier__min_child_samples': [10, 20, 30],\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'classifier__reg_alpha': [0.0, 0.1, 0.5],\n",
    "    'classifier__scale_pos_weight': [1, 2, 5]\n",
    "}\n",
    "\n",
    "\n",
    "# Define the classifier\n",
    "lgm_cls = lgb.LGBMClassifier()\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_lgm_cls = Pipeline(steps=[\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', lgm_cls)\n",
    "])\n",
    "\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_lgm_cls = GridSearchCV(pipe_lgm_cls, param_grid, cv=5, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_lgm_cls.fit(X, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_lgm_cls.best_params_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_lgm_cls.best_estimator_\n",
    "\n",
    "# Use the best model for prediction\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;target&#x27;,\n",
       "                                                                         TargetEncoder(),\n",
       "                                                                         [&#x27;BalanceCredit&#x27;,\n",
       "                                                                          &#x27;AgeProducts&#x27;,\n",
       "                                                                          &#x27;SatisfactionProducts&#x27;,\n",
       "                                                                          &#x27;CardProducts&#x27;,\n",
       "                                                                          &#x27;TenurePoints&#x27;]),\n",
       "                                                                        (&#x27;scaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;CreditScore&#x27;,\n",
       "                                                                          &#x27;Age&#x27;,\n",
       "                                                                          &#x27;Balance&#x27;,\n",
       "                                                                          &#x27;NumOfProducts&#x27;,\n",
       "                                                                          &#x27;EstimatedSalary&#x27;,\n",
       "                                                                          &#x27;PointsEarned&#x27;]),\n",
       "                                                                        (&#x27;ordinal&#x27;,\n",
       "                                                                         &#x27;passthrough&#x27;,\n",
       "                                                                         [&#x27;Tenure&#x27;,\n",
       "                                                                          &#x27;C...\n",
       "                                       (&#x27;classifier&#x27;, LGBMClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__learning_rate&#x27;: [0.01, 0.1],\n",
       "                         &#x27;classifier__max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;classifier__min_child_samples&#x27;: [10, 20, 30],\n",
       "                         &#x27;classifier__num_leaves&#x27;: [10, 20, 30],\n",
       "                         &#x27;classifier__reg_alpha&#x27;: [0.0, 0.1, 0.5],\n",
       "                         &#x27;classifier__scale_pos_weight&#x27;: [1, 2, 5],\n",
       "                         &#x27;classifier__subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;target&#x27;,\n",
       "                                                                         TargetEncoder(),\n",
       "                                                                         [&#x27;BalanceCredit&#x27;,\n",
       "                                                                          &#x27;AgeProducts&#x27;,\n",
       "                                                                          &#x27;SatisfactionProducts&#x27;,\n",
       "                                                                          &#x27;CardProducts&#x27;,\n",
       "                                                                          &#x27;TenurePoints&#x27;]),\n",
       "                                                                        (&#x27;scaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;CreditScore&#x27;,\n",
       "                                                                          &#x27;Age&#x27;,\n",
       "                                                                          &#x27;Balance&#x27;,\n",
       "                                                                          &#x27;NumOfProducts&#x27;,\n",
       "                                                                          &#x27;EstimatedSalary&#x27;,\n",
       "                                                                          &#x27;PointsEarned&#x27;]),\n",
       "                                                                        (&#x27;ordinal&#x27;,\n",
       "                                                                         &#x27;passthrough&#x27;,\n",
       "                                                                         [&#x27;Tenure&#x27;,\n",
       "                                                                          &#x27;C...\n",
       "                                       (&#x27;classifier&#x27;, LGBMClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__learning_rate&#x27;: [0.01, 0.1],\n",
       "                         &#x27;classifier__max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;classifier__min_child_samples&#x27;: [10, 20, 30],\n",
       "                         &#x27;classifier__num_leaves&#x27;: [10, 20, 30],\n",
       "                         &#x27;classifier__reg_alpha&#x27;: [0.0, 0.1, 0.5],\n",
       "                         &#x27;classifier__scale_pos_weight&#x27;: [1, 2, 5],\n",
       "                         &#x27;classifier__subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;target&#x27;, TargetEncoder(),\n",
       "                                                  [&#x27;BalanceCredit&#x27;,\n",
       "                                                   &#x27;AgeProducts&#x27;,\n",
       "                                                   &#x27;SatisfactionProducts&#x27;,\n",
       "                                                   &#x27;CardProducts&#x27;,\n",
       "                                                   &#x27;TenurePoints&#x27;]),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;,\n",
       "                                                   &#x27;PointsEarned&#x27;]),\n",
       "                                                 (&#x27;ordinal&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;Tenure&#x27;, &#x27;CardTypeOrd&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;]),\n",
       "                                                 (&#x27;cluster&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;ClusterKMeans&#x27;,\n",
       "                                                   &#x27;ClusterBGM&#x27;]),\n",
       "                                                 (&#x27;categorical&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;GenderBinary&#x27;,\n",
       "                                                   &#x27;GenderBinary&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LGBMClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;target&#x27;, TargetEncoder(),\n",
       "                                 [&#x27;BalanceCredit&#x27;, &#x27;AgeProducts&#x27;,\n",
       "                                  &#x27;SatisfactionProducts&#x27;, &#x27;CardProducts&#x27;,\n",
       "                                  &#x27;TenurePoints&#x27;]),\n",
       "                                (&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Balance&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;, &#x27;EstimatedSalary&#x27;,\n",
       "                                  &#x27;PointsEarned&#x27;]),\n",
       "                                (&#x27;ordinal&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;Tenure&#x27;, &#x27;CardTypeOrd&#x27;, &#x27;NumOfProducts&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;]),\n",
       "                                (&#x27;cluster&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;ClusterKMeans&#x27;, &#x27;ClusterBGM&#x27;]),\n",
       "                                (&#x27;categorical&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;GenderBinary&#x27;,\n",
       "                                  &#x27;GenderBinary&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">target</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BalanceCredit&#x27;, &#x27;AgeProducts&#x27;, &#x27;SatisfactionProducts&#x27;, &#x27;CardProducts&#x27;, &#x27;TenurePoints&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TargetEncoder</label><div class=\"sk-toggleable__content\"><pre>TargetEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;, &#x27;EstimatedSalary&#x27;, &#x27;PointsEarned&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Tenure&#x27;, &#x27;CardTypeOrd&#x27;, &#x27;NumOfProducts&#x27;, &#x27;NumOfProducts&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cluster</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ClusterKMeans&#x27;, &#x27;ClusterBGM&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;GenderBinary&#x27;, &#x27;GenderBinary&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('target',\n",
       "                                                                         TargetEncoder(),\n",
       "                                                                         ['BalanceCredit',\n",
       "                                                                          'AgeProducts',\n",
       "                                                                          'SatisfactionProducts',\n",
       "                                                                          'CardProducts',\n",
       "                                                                          'TenurePoints']),\n",
       "                                                                        ('scaler',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['CreditScore',\n",
       "                                                                          'Age',\n",
       "                                                                          'Balance',\n",
       "                                                                          'NumOfProducts',\n",
       "                                                                          'EstimatedSalary',\n",
       "                                                                          'PointsEarned']),\n",
       "                                                                        ('ordinal',\n",
       "                                                                         'passthrough',\n",
       "                                                                         ['Tenure',\n",
       "                                                                          'C...\n",
       "                                       ('classifier', LGBMClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__learning_rate': [0.01, 0.1],\n",
       "                         'classifier__max_depth': [3, 5, 7],\n",
       "                         'classifier__min_child_samples': [10, 20, 30],\n",
       "                         'classifier__num_leaves': [10, 20, 30],\n",
       "                         'classifier__reg_alpha': [0.0, 0.1, 0.5],\n",
       "                         'classifier__scale_pos_weight': [1, 2, 5],\n",
       "                         'classifier__subsample': [0.6, 0.8, 1.0]},\n",
       "             scoring='f1_macro', verbose=4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#! LGBMClassifier\n",
    "\n",
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned']\n",
    "continuous_features_engine = ['BalanceCredit', 'AgeProducts', 'SatisfactionProducts', 'CardProducts', 'TenurePoints']\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary', 'GenderBinary']\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "\n",
    "# Define the classifier\n",
    "lgm_cls = lgb.LGBMClassifier()\n",
    "\n",
    "# Define the parameter grid for the LGBMClassifier estimator\n",
    "lgm_cls_params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.8],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'num_leaves': [10, 20, 30],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0.0, 0.1, 0.5],\n",
    "    'scale_pos_weight': [1, 2, 5]\n",
    "}\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), continuous_features_engine),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "\n",
    "# Update the parameter grid to include the parameters of the LGBMClassifier estimator\n",
    "param_grid = {\n",
    "    'classifier__' + k: v for k, v in lgm_cls_params.items()\n",
    "}\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_lgm_cls = Pipeline(steps=[\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', lgm_cls)\n",
    "])\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_lgm_cls = GridSearchCV(pipe_lgm_cls, param_grid, cv=5, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_lgm_cls.fit(X, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_lgm_cls.best_params_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_lgm_cls.best_estimator_\n",
    "\n",
    "# Use the best model for prediction\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_samples': 10, 'classifier__num_leaves': 10, 'classifier__reg_alpha': 0.0, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.6}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       796\n",
      "           1       0.62      0.60      0.61       204\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.76      0.75      0.76      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Best Parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_samples': 10, 'classifier__num_leaves': 10, 'classifier__reg_alpha': 0.0, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.6}\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.91      0.90       796\n",
    "           1       0.62      0.60      0.61       204\n",
    "\n",
    "    accuracy                           0.84      1000\n",
    "   macro avg       0.76      0.75      0.76      1000\n",
    "weighted avg       0.84      0.84      0.84      1000\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
    "Best Parameters: {'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
    "Best Score (F1 Macro): 0.7037421002959607\n",
    "Model name:  RandomForestClassifier\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.99      0.93       796\n",
    "           1       0.89      0.44      0.59       204\n",
    "\n",
    "    accuracy                           0.87      1000\n",
    "   macro avg       0.88      0.71      0.76      1000\n",
    "weighted avg       0.88      0.87      0.86      1000\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'classifier__learning_rate': 0.25, 'classifier__max_depth': 7, 'classifier__num_leaves': 30}\n",
      "Best Score (F1 Macro): 0.7354734319564414\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88       796\n",
      "           1       0.53      0.59      0.56       204\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.71      0.73      0.72      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned']\n",
    "continuous_features_engine = ['BalanceCredit', 'AgeProducts', 'SatisfactionProducts', 'CardProducts', 'TenurePoints']\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary', 'GenderBinary']\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "\n",
    "# Increase the weight value in proportion to its frequency to balance a bit for the current undersampling\n",
    "class_weights = dict(zip(np.unique(y_train), [len(y_train) / (len(np.unique(y_train)) * np.bincount(y_train)[i]) for i in np.unique(y_train)]))\n",
    "\n",
    "\n",
    "# Create an instance of the LGBMClassifier\n",
    "lgm = lgb.LGBMClassifier(class_weight=class_weights)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__num_leaves': [20,25,30],\n",
    "    'classifier__max_depth': [7,8,9],\n",
    "    'classifier__learning_rate': [0.05, 0.1,0.2,0.25]\n",
    "}\n",
    "\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), continuous_features_engine),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_lgm_cls_222 = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', lgm)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_lgm_222 = GridSearchCV(pipe_lgm_cls_222, param_grid, cv=3, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_lgm_222.fit(X, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_lgm_222.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_lgm_222.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_lgm_222.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
    "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
    "Best Parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 7, 'classifier__num_leaves': 20}\n",
    "Best Score (F1 Macro): 0.7398664837604242\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.96      0.92       796\n",
    "           1       0.78      0.54      0.64       204\n",
    "\n",
    "    accuracy                           0.88      1000\n",
    "   macro avg       0.84      0.75      0.78      1000\n",
    "weighted avg       0.87      0.88      0.87      1000\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'classifier__C': 1.0, 'classifier__penalty': 'l2'}\n",
      "Best Score (F1 Macro): 0.6389185818926236\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78       796\n",
      "           1       0.36      0.70      0.48       204\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.63      0.69      0.63      1000\n",
      "weighted avg       0.79      0.69      0.72      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_enc_features = ['GenderBinary', 'CountryOrd', 'SurnameOrd', 'HasCrCard', 'IsActiveMember', 'Tenure', 'NumOfProducts',\n",
    "                       'SatisfactionScore', 'PointsEarnedQuant', 'AgeOrd', 'TaxBracket', 'BalanceOrd']\n",
    "\n",
    "\n",
    "# Increase the weight value in proportion to its frequency to balance a bit for the current undersampling\n",
    "class_weights = dict(zip(np.unique(y_train), [len(y_train) / (len(np.unique(y_train)) * np.bincount(y_train)[i]) for i in np.unique(y_train)]))\n",
    "\n",
    "\n",
    "# Create an instance of the LGBMClassifier\n",
    "logreg = LogisticRegression(class_weight=class_weights) # class_weight=class_weights\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1.0, 10.0],\n",
    "    'classifier__penalty': ['l2']\n",
    "}\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('target_encoder', TargetEncoder(), target_enc_features),\n",
    "])\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_logReg = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', logreg)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(pipe_logReg, param_grid, cv=5, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n",
      "Best Score (F1 Macro): 0.690685149293826\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83       796\n",
      "           1       0.43      0.69      0.53       204\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.67      0.73      0.68      1000\n",
      "weighted avg       0.81      0.75      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned']\n",
    "continuous_features_engine = ['BalanceCredit', 'AgeProducts', 'SatisfactionProducts', 'CardProducts', 'TenurePoints']\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary', 'GenderBinary']\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "\n",
    "# Increase the weight value in proportion to its frequency to balance a bit for the current undersampling\n",
    "class_weights = dict(zip(np.unique(y_train), [len(y_train) / (len(np.unique(y_train)) * np.bincount(y_train)[i]) for i in np.unique(y_train)]))\n",
    "\n",
    "\n",
    "# Create an instance of the LGBMClassifier\n",
    "# lgm = lgb.LGBMClassifier(class_weight=class_weights)\n",
    "logreg = LogisticRegression(max_iter=1500 ,class_weight=class_weights) # class_weight=class_weights\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1.0, 10.0],\n",
    "    'classifier__penalty': ['l2']\n",
    "}\n",
    "\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), continuous_features_engine),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_log_reg = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', logreg)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_log_reg = GridSearchCV(pipe_log_reg, param_grid, cv=3, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_log_reg.fit(X, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_log_reg.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_log_reg.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_log_reg.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
    "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
    "Best Parameters: {'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n",
    "Best Score (F1 Macro): 0.690685149293826\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.77      0.83       796\n",
    "           1       0.43      0.69      0.53       204\n",
    "\n",
    "    accuracy                           0.75      1000\n",
    "   macro avg       0.67      0.73      0.68      1000\n",
    "weighted avg       0.81      0.75      0.77      1000\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "0:\tlearn: 0.6644162\ttotal: 18.8ms\tremaining: 3.74s\n",
      "1:\tlearn: 0.6431847\ttotal: 36.9ms\tremaining: 3.65s\n",
      "2:\tlearn: 0.6239523\ttotal: 56.7ms\tremaining: 3.72s\n",
      "3:\tlearn: 0.6073529\ttotal: 75.9ms\tremaining: 3.72s\n",
      "4:\tlearn: 0.5924002\ttotal: 91.5ms\tremaining: 3.57s\n",
      "5:\tlearn: 0.5823188\ttotal: 107ms\tremaining: 3.47s\n",
      "6:\tlearn: 0.5653201\ttotal: 132ms\tremaining: 3.63s\n",
      "7:\tlearn: 0.5526096\ttotal: 165ms\tremaining: 3.95s\n",
      "8:\tlearn: 0.5432181\ttotal: 223ms\tremaining: 4.72s\n",
      "9:\tlearn: 0.5325088\ttotal: 247ms\tremaining: 4.69s\n",
      "10:\tlearn: 0.5255730\ttotal: 285ms\tremaining: 4.89s\n",
      "11:\tlearn: 0.5180769\ttotal: 314ms\tremaining: 4.92s\n",
      "12:\tlearn: 0.5127119\ttotal: 335ms\tremaining: 4.82s\n",
      "13:\tlearn: 0.5081483\ttotal: 356ms\tremaining: 4.74s\n",
      "14:\tlearn: 0.5031399\ttotal: 384ms\tremaining: 4.74s\n",
      "15:\tlearn: 0.4976469\ttotal: 410ms\tremaining: 4.71s\n",
      "16:\tlearn: 0.4948376\ttotal: 436ms\tremaining: 4.69s\n",
      "17:\tlearn: 0.4891475\ttotal: 482ms\tremaining: 4.87s\n",
      "18:\tlearn: 0.4836258\ttotal: 518ms\tremaining: 4.93s\n",
      "19:\tlearn: 0.4794706\ttotal: 551ms\tremaining: 4.96s\n",
      "20:\tlearn: 0.4758907\ttotal: 583ms\tremaining: 4.97s\n",
      "21:\tlearn: 0.4724320\ttotal: 610ms\tremaining: 4.93s\n",
      "22:\tlearn: 0.4679312\ttotal: 629ms\tremaining: 4.84s\n",
      "23:\tlearn: 0.4657869\ttotal: 656ms\tremaining: 4.81s\n",
      "24:\tlearn: 0.4623400\ttotal: 674ms\tremaining: 4.72s\n",
      "25:\tlearn: 0.4590151\ttotal: 694ms\tremaining: 4.65s\n",
      "26:\tlearn: 0.4564528\ttotal: 710ms\tremaining: 4.55s\n",
      "27:\tlearn: 0.4524593\ttotal: 735ms\tremaining: 4.52s\n",
      "28:\tlearn: 0.4500694\ttotal: 755ms\tremaining: 4.45s\n",
      "29:\tlearn: 0.4472474\ttotal: 781ms\tremaining: 4.43s\n",
      "30:\tlearn: 0.4437245\ttotal: 805ms\tremaining: 4.39s\n",
      "31:\tlearn: 0.4415007\ttotal: 826ms\tremaining: 4.33s\n",
      "32:\tlearn: 0.4387949\ttotal: 857ms\tremaining: 4.34s\n",
      "33:\tlearn: 0.4359110\ttotal: 879ms\tremaining: 4.29s\n",
      "34:\tlearn: 0.4341637\ttotal: 900ms\tremaining: 4.24s\n",
      "35:\tlearn: 0.4324884\ttotal: 919ms\tremaining: 4.19s\n",
      "36:\tlearn: 0.4289307\ttotal: 939ms\tremaining: 4.13s\n",
      "37:\tlearn: 0.4264026\ttotal: 967ms\tremaining: 4.12s\n",
      "38:\tlearn: 0.4240752\ttotal: 987ms\tremaining: 4.08s\n",
      "39:\tlearn: 0.4213473\ttotal: 1.01s\tremaining: 4.05s\n",
      "40:\tlearn: 0.4188605\ttotal: 1.04s\tremaining: 4.04s\n",
      "41:\tlearn: 0.4149774\ttotal: 1.06s\tremaining: 3.99s\n",
      "42:\tlearn: 0.4123321\ttotal: 1.08s\tremaining: 3.95s\n",
      "43:\tlearn: 0.4114169\ttotal: 1.1s\tremaining: 3.9s\n",
      "44:\tlearn: 0.4087215\ttotal: 1.13s\tremaining: 3.89s\n",
      "45:\tlearn: 0.4075725\ttotal: 1.15s\tremaining: 3.84s\n",
      "46:\tlearn: 0.4044499\ttotal: 1.17s\tremaining: 3.81s\n",
      "47:\tlearn: 0.4022962\ttotal: 1.2s\tremaining: 3.79s\n",
      "48:\tlearn: 0.4001549\ttotal: 1.22s\tremaining: 3.76s\n",
      "49:\tlearn: 0.3985155\ttotal: 1.25s\tremaining: 3.74s\n",
      "50:\tlearn: 0.3964593\ttotal: 1.27s\tremaining: 3.71s\n",
      "51:\tlearn: 0.3945220\ttotal: 1.3s\tremaining: 3.7s\n",
      "52:\tlearn: 0.3932373\ttotal: 1.32s\tremaining: 3.66s\n",
      "53:\tlearn: 0.3910024\ttotal: 1.34s\tremaining: 3.63s\n",
      "54:\tlearn: 0.3893359\ttotal: 1.37s\tremaining: 3.61s\n",
      "55:\tlearn: 0.3876541\ttotal: 1.4s\tremaining: 3.59s\n",
      "56:\tlearn: 0.3850398\ttotal: 1.42s\tremaining: 3.57s\n",
      "57:\tlearn: 0.3830005\ttotal: 1.45s\tremaining: 3.55s\n",
      "58:\tlearn: 0.3813923\ttotal: 1.47s\tremaining: 3.52s\n",
      "59:\tlearn: 0.3806091\ttotal: 1.5s\tremaining: 3.49s\n",
      "60:\tlearn: 0.3798860\ttotal: 1.53s\tremaining: 3.48s\n",
      "61:\tlearn: 0.3787332\ttotal: 1.55s\tremaining: 3.46s\n",
      "62:\tlearn: 0.3757925\ttotal: 1.58s\tremaining: 3.44s\n",
      "63:\tlearn: 0.3742634\ttotal: 1.61s\tremaining: 3.41s\n",
      "64:\tlearn: 0.3742335\ttotal: 1.61s\tremaining: 3.35s\n",
      "65:\tlearn: 0.3720111\ttotal: 1.64s\tremaining: 3.33s\n",
      "66:\tlearn: 0.3711545\ttotal: 1.66s\tremaining: 3.3s\n",
      "67:\tlearn: 0.3691556\ttotal: 1.68s\tremaining: 3.27s\n",
      "68:\tlearn: 0.3668139\ttotal: 1.71s\tremaining: 3.24s\n",
      "69:\tlearn: 0.3660649\ttotal: 1.73s\tremaining: 3.21s\n",
      "70:\tlearn: 0.3639377\ttotal: 1.75s\tremaining: 3.18s\n",
      "71:\tlearn: 0.3622151\ttotal: 1.77s\tremaining: 3.15s\n",
      "72:\tlearn: 0.3596052\ttotal: 1.79s\tremaining: 3.12s\n",
      "73:\tlearn: 0.3586207\ttotal: 1.81s\tremaining: 3.08s\n",
      "74:\tlearn: 0.3578771\ttotal: 1.83s\tremaining: 3.05s\n",
      "75:\tlearn: 0.3566805\ttotal: 1.85s\tremaining: 3.02s\n",
      "76:\tlearn: 0.3545689\ttotal: 1.88s\tremaining: 3s\n",
      "77:\tlearn: 0.3541079\ttotal: 1.91s\tremaining: 2.98s\n",
      "78:\tlearn: 0.3513695\ttotal: 1.93s\tremaining: 2.95s\n",
      "79:\tlearn: 0.3498089\ttotal: 1.95s\tremaining: 2.93s\n",
      "80:\tlearn: 0.3491377\ttotal: 1.97s\tremaining: 2.9s\n",
      "81:\tlearn: 0.3472777\ttotal: 2s\tremaining: 2.87s\n",
      "82:\tlearn: 0.3458647\ttotal: 2.02s\tremaining: 2.84s\n",
      "83:\tlearn: 0.3442850\ttotal: 2.04s\tremaining: 2.81s\n",
      "84:\tlearn: 0.3423980\ttotal: 2.06s\tremaining: 2.78s\n",
      "85:\tlearn: 0.3407903\ttotal: 2.07s\tremaining: 2.75s\n",
      "86:\tlearn: 0.3389021\ttotal: 2.09s\tremaining: 2.72s\n",
      "87:\tlearn: 0.3379658\ttotal: 2.11s\tremaining: 2.69s\n",
      "88:\tlearn: 0.3349209\ttotal: 2.13s\tremaining: 2.66s\n",
      "89:\tlearn: 0.3327310\ttotal: 2.15s\tremaining: 2.63s\n",
      "90:\tlearn: 0.3316058\ttotal: 2.17s\tremaining: 2.61s\n",
      "91:\tlearn: 0.3303788\ttotal: 2.2s\tremaining: 2.58s\n",
      "92:\tlearn: 0.3293566\ttotal: 2.22s\tremaining: 2.55s\n",
      "93:\tlearn: 0.3284580\ttotal: 2.24s\tremaining: 2.52s\n",
      "94:\tlearn: 0.3270335\ttotal: 2.26s\tremaining: 2.49s\n",
      "95:\tlearn: 0.3252548\ttotal: 2.28s\tremaining: 2.47s\n",
      "96:\tlearn: 0.3235329\ttotal: 2.3s\tremaining: 2.44s\n",
      "97:\tlearn: 0.3214493\ttotal: 2.32s\tremaining: 2.42s\n",
      "98:\tlearn: 0.3208261\ttotal: 2.34s\tremaining: 2.39s\n",
      "99:\tlearn: 0.3188312\ttotal: 2.36s\tremaining: 2.36s\n",
      "100:\tlearn: 0.3179416\ttotal: 2.38s\tremaining: 2.33s\n",
      "101:\tlearn: 0.3171519\ttotal: 2.4s\tremaining: 2.31s\n",
      "102:\tlearn: 0.3162016\ttotal: 2.42s\tremaining: 2.28s\n",
      "103:\tlearn: 0.3149152\ttotal: 2.44s\tremaining: 2.25s\n",
      "104:\tlearn: 0.3144984\ttotal: 2.46s\tremaining: 2.23s\n",
      "105:\tlearn: 0.3136025\ttotal: 2.48s\tremaining: 2.2s\n",
      "106:\tlearn: 0.3111618\ttotal: 2.5s\tremaining: 2.17s\n",
      "107:\tlearn: 0.3096450\ttotal: 2.52s\tremaining: 2.15s\n",
      "108:\tlearn: 0.3080434\ttotal: 2.54s\tremaining: 2.12s\n",
      "109:\tlearn: 0.3068818\ttotal: 2.57s\tremaining: 2.1s\n",
      "110:\tlearn: 0.3056301\ttotal: 2.59s\tremaining: 2.07s\n",
      "111:\tlearn: 0.3040506\ttotal: 2.61s\tremaining: 2.05s\n",
      "112:\tlearn: 0.3027946\ttotal: 2.63s\tremaining: 2.02s\n",
      "113:\tlearn: 0.3019473\ttotal: 2.65s\tremaining: 2s\n",
      "114:\tlearn: 0.3011623\ttotal: 2.67s\tremaining: 1.97s\n",
      "115:\tlearn: 0.2996485\ttotal: 2.69s\tremaining: 1.94s\n",
      "116:\tlearn: 0.2988725\ttotal: 2.71s\tremaining: 1.92s\n",
      "117:\tlearn: 0.2978845\ttotal: 2.73s\tremaining: 1.9s\n",
      "118:\tlearn: 0.2974405\ttotal: 2.75s\tremaining: 1.87s\n",
      "119:\tlearn: 0.2963723\ttotal: 2.77s\tremaining: 1.85s\n",
      "120:\tlearn: 0.2956443\ttotal: 2.79s\tremaining: 1.82s\n",
      "121:\tlearn: 0.2938458\ttotal: 2.81s\tremaining: 1.8s\n",
      "122:\tlearn: 0.2926192\ttotal: 2.83s\tremaining: 1.77s\n",
      "123:\tlearn: 0.2910286\ttotal: 2.85s\tremaining: 1.75s\n",
      "124:\tlearn: 0.2901427\ttotal: 2.87s\tremaining: 1.72s\n",
      "125:\tlearn: 0.2894867\ttotal: 2.89s\tremaining: 1.7s\n",
      "126:\tlearn: 0.2885308\ttotal: 2.91s\tremaining: 1.68s\n",
      "127:\tlearn: 0.2865083\ttotal: 2.93s\tremaining: 1.65s\n",
      "128:\tlearn: 0.2845665\ttotal: 2.95s\tremaining: 1.63s\n",
      "129:\tlearn: 0.2835901\ttotal: 2.97s\tremaining: 1.6s\n",
      "130:\tlearn: 0.2817733\ttotal: 2.99s\tremaining: 1.58s\n",
      "131:\tlearn: 0.2811786\ttotal: 3.01s\tremaining: 1.55s\n",
      "132:\tlearn: 0.2799434\ttotal: 3.03s\tremaining: 1.52s\n",
      "133:\tlearn: 0.2780041\ttotal: 3.05s\tremaining: 1.5s\n",
      "134:\tlearn: 0.2771313\ttotal: 3.07s\tremaining: 1.48s\n",
      "135:\tlearn: 0.2762177\ttotal: 3.09s\tremaining: 1.46s\n",
      "136:\tlearn: 0.2755516\ttotal: 3.11s\tremaining: 1.43s\n",
      "137:\tlearn: 0.2743910\ttotal: 3.13s\tremaining: 1.41s\n",
      "138:\tlearn: 0.2735625\ttotal: 3.19s\tremaining: 1.4s\n",
      "139:\tlearn: 0.2716520\ttotal: 3.21s\tremaining: 1.37s\n",
      "140:\tlearn: 0.2703737\ttotal: 3.23s\tremaining: 1.35s\n",
      "141:\tlearn: 0.2693118\ttotal: 3.26s\tremaining: 1.33s\n",
      "142:\tlearn: 0.2686485\ttotal: 3.28s\tremaining: 1.31s\n",
      "143:\tlearn: 0.2679953\ttotal: 3.31s\tremaining: 1.29s\n",
      "144:\tlearn: 0.2666257\ttotal: 3.34s\tremaining: 1.27s\n",
      "145:\tlearn: 0.2644517\ttotal: 3.38s\tremaining: 1.25s\n",
      "146:\tlearn: 0.2631995\ttotal: 3.41s\tremaining: 1.23s\n",
      "147:\tlearn: 0.2627209\ttotal: 3.43s\tremaining: 1.21s\n",
      "148:\tlearn: 0.2609456\ttotal: 3.46s\tremaining: 1.19s\n",
      "149:\tlearn: 0.2602596\ttotal: 3.5s\tremaining: 1.17s\n",
      "150:\tlearn: 0.2592175\ttotal: 3.52s\tremaining: 1.14s\n",
      "151:\tlearn: 0.2581159\ttotal: 3.54s\tremaining: 1.12s\n",
      "152:\tlearn: 0.2572610\ttotal: 3.57s\tremaining: 1.1s\n",
      "153:\tlearn: 0.2563162\ttotal: 3.59s\tremaining: 1.07s\n",
      "154:\tlearn: 0.2560868\ttotal: 3.61s\tremaining: 1.05s\n",
      "155:\tlearn: 0.2544469\ttotal: 3.63s\tremaining: 1.02s\n",
      "156:\tlearn: 0.2528067\ttotal: 3.65s\tremaining: 1s\n",
      "157:\tlearn: 0.2524596\ttotal: 3.67s\tremaining: 977ms\n",
      "158:\tlearn: 0.2515038\ttotal: 3.69s\tremaining: 953ms\n",
      "159:\tlearn: 0.2508736\ttotal: 3.72s\tremaining: 929ms\n",
      "160:\tlearn: 0.2501727\ttotal: 3.74s\tremaining: 906ms\n",
      "161:\tlearn: 0.2489945\ttotal: 3.77s\tremaining: 883ms\n",
      "162:\tlearn: 0.2472067\ttotal: 3.84s\tremaining: 872ms\n",
      "163:\tlearn: 0.2465332\ttotal: 3.86s\tremaining: 848ms\n",
      "164:\tlearn: 0.2460103\ttotal: 3.88s\tremaining: 824ms\n",
      "165:\tlearn: 0.2449552\ttotal: 3.91s\tremaining: 800ms\n",
      "166:\tlearn: 0.2442813\ttotal: 3.94s\tremaining: 779ms\n",
      "167:\tlearn: 0.2434261\ttotal: 3.97s\tremaining: 756ms\n",
      "168:\tlearn: 0.2422328\ttotal: 3.99s\tremaining: 732ms\n",
      "169:\tlearn: 0.2416433\ttotal: 4.01s\tremaining: 708ms\n",
      "170:\tlearn: 0.2407949\ttotal: 4.04s\tremaining: 686ms\n",
      "171:\tlearn: 0.2399705\ttotal: 4.07s\tremaining: 663ms\n",
      "172:\tlearn: 0.2394245\ttotal: 4.09s\tremaining: 639ms\n",
      "173:\tlearn: 0.2388348\ttotal: 4.12s\tremaining: 616ms\n",
      "174:\tlearn: 0.2375572\ttotal: 4.14s\tremaining: 592ms\n",
      "175:\tlearn: 0.2363620\ttotal: 4.17s\tremaining: 568ms\n",
      "176:\tlearn: 0.2359309\ttotal: 4.19s\tremaining: 545ms\n",
      "177:\tlearn: 0.2347302\ttotal: 4.22s\tremaining: 522ms\n",
      "178:\tlearn: 0.2338007\ttotal: 4.25s\tremaining: 499ms\n",
      "179:\tlearn: 0.2327375\ttotal: 4.27s\tremaining: 475ms\n",
      "180:\tlearn: 0.2317154\ttotal: 4.3s\tremaining: 451ms\n",
      "181:\tlearn: 0.2304586\ttotal: 4.32s\tremaining: 427ms\n",
      "182:\tlearn: 0.2294972\ttotal: 4.34s\tremaining: 403ms\n",
      "183:\tlearn: 0.2284031\ttotal: 4.35s\tremaining: 379ms\n",
      "184:\tlearn: 0.2269205\ttotal: 4.38s\tremaining: 355ms\n",
      "185:\tlearn: 0.2260475\ttotal: 4.4s\tremaining: 332ms\n",
      "186:\tlearn: 0.2253511\ttotal: 4.43s\tremaining: 308ms\n",
      "187:\tlearn: 0.2243766\ttotal: 4.45s\tremaining: 284ms\n",
      "188:\tlearn: 0.2239781\ttotal: 4.46s\tremaining: 260ms\n",
      "189:\tlearn: 0.2234163\ttotal: 4.48s\tremaining: 236ms\n",
      "190:\tlearn: 0.2226306\ttotal: 4.5s\tremaining: 212ms\n",
      "191:\tlearn: 0.2218495\ttotal: 4.52s\tremaining: 188ms\n",
      "192:\tlearn: 0.2207224\ttotal: 4.55s\tremaining: 165ms\n",
      "193:\tlearn: 0.2195953\ttotal: 4.57s\tremaining: 141ms\n",
      "194:\tlearn: 0.2189941\ttotal: 4.6s\tremaining: 118ms\n",
      "195:\tlearn: 0.2180875\ttotal: 4.62s\tremaining: 94.4ms\n",
      "196:\tlearn: 0.2173788\ttotal: 4.65s\tremaining: 70.9ms\n",
      "197:\tlearn: 0.2167805\ttotal: 4.68s\tremaining: 47.3ms\n",
      "198:\tlearn: 0.2158454\ttotal: 4.7s\tremaining: 23.6ms\n",
      "199:\tlearn: 0.2151628\ttotal: 4.71s\tremaining: 0us\n",
      "Best Parameters: {'classifier__colsample_bylevel': 0.8, 'classifier__depth': 9, 'classifier__l2_leaf_reg': 1, 'classifier__learning_rate': 0.05, 'classifier__n_estimators': 200, 'classifier__subsample': 0.8}\n",
      "Best Score (F1 Macro): 0.7402284236119909\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89       796\n",
      "           1       0.56      0.64      0.60       204\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.73      0.76      0.74      1000\n",
      "weighted avg       0.83      0.82      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned']\n",
    "continuous_features_engine = ['BalanceCredit', 'AgeProducts', 'SatisfactionProducts', 'CardProducts', 'TenurePoints']\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary', 'GenderBinary']\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "\n",
    "# Increase the weight value in proportion to its frequency to balance a bit for the current undersampling\n",
    "class_weights = dict(zip(np.unique(y_train), [len(y_train) / (len(np.unique(y_train)) * np.bincount(y_train)[i]) for i in np.unique(y_train)]))\n",
    "\n",
    "\n",
    "catboost_cls = CatBoostClassifier(class_weights=class_weights)\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'classifier__learning_rate': [0.05, 0.1, 0.15],\n",
    "#     'classifier__depth': [3, 5, 7, 9],\n",
    "#     'classifier__n_estimators': [150, 200, 300]\n",
    "# }\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.15],\n",
    "    'classifier__depth': [3, 5, 7, 9],\n",
    "    'classifier__n_estimators': [150, 200, 300],\n",
    "    'classifier__l2_leaf_reg': [1, 3, 5],\n",
    "    'classifier__subsample': [0.8, 1.0],\n",
    "    'classifier__colsample_bylevel': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), continuous_features_engine),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_catboost_cls = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', catboost_cls)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_catboost_cls = GridSearchCV(pipe_catboost_cls, param_grid, cv=3, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_catboost_cls.fit(X, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_catboost_cls.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_catboost_cls.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_catboost_cls.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Best Parameters: {'classifier__colsample_bylevel': 0.8, 'classifier__depth': 9, 'classifier__l2_leaf_reg': 1, 'classifier__learning_rate': 0.05, 'classifier__n_estimators': 200, 'classifier__subsample': 0.8}\n",
    "Best Score (F1 Macro): 0.7402284236119909\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.87      0.89       796\n",
    "           1       0.56      0.64      0.60       204\n",
    "\n",
    "    accuracy                           0.82      1000\n",
    "   macro avg       0.73      0.76      0.74      1000\n",
    "weighted avg       0.83      0.82      0.83      1000\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best Parameters: {'classifier__learning_rate': 0.05, 'classifier__max_depth': 5, 'classifier__n_estimators': 150}\n",
      "Best Score (F1 Macro): 0.7315665204230263\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       796\n",
      "           1       0.75      0.45      0.56       204\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.81      0.70      0.74      1000\n",
      "weighted avg       0.85      0.86      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#* With semi-duplicate features i.e. Balance AND BalanceCredit\n",
    "\n",
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned', 'TenurePoints', 'CardProducts', 'SatisfactionProducts', 'AgeProducts', 'BalanceCredit']\n",
    "\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary']\n",
    "\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "target_enc_features = ['GenderBinary', 'CountryOrd', 'SurnameOrd', 'HasCrCard', 'IsActiveMember',  'Tenure', 'NumOfProducts','SatisfactionScore', 'TenurePoints', 'CardProducts', 'SatisfactionProducts', 'AgeProducts', 'BalanceCredit']\n",
    "\n",
    "# Increase the weight value in proportion to its frequency to balance a bit for the current undersampling\n",
    "class_weights = dict(zip(np.unique(y_train), [len(y_train) / (len(np.unique(y_train)) * np.bincount(y_train)[i]) for i in np.unique(y_train)]))\n",
    "\n",
    "# Create an instance of the XGBClassifier\n",
    "xgb_cls = XGBClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.15],\n",
    "    'classifier__max_depth': [3, 5, 7,9],\n",
    "    'classifier__n_estimators': [150, 200, 300]\n",
    "}\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_xgb_cls = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', xgb_cls)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_xg = GridSearchCV(pipe_xgb_cls, param_grid, cv=3, scoring='f1_macro', verbose=4, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_xg.fit(X, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_xg.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_xg.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_xg.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
    "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
    "Best Parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 300}\n",
    "Best Score (F1 Macro): 0.7385244777083596\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.96      0.91       796\n",
    "           1       0.73      0.47      0.57       204\n",
    "\n",
    "    accuracy                           0.86      1000\n",
    "   macro avg       0.80      0.71      0.74      1000\n",
    "weighted avg       0.85      0.86      0.84      1000\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> \n",
    "After testing some typical models that are used for binary classification. I think the best model is catboost. Though there are definitely more hyperparameters to test that i did not have the time for this time.\n",
    "\n",
    "Lastly i will try some other configurations with catboost and then try the best scoring on the X_test set and save that model.  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# y_train_series = pd.Series(y_train)\n",
    "y_train = pd.read_csv(\"y_train_tran.csv\")\n",
    "\n",
    "# Combine X_train and y_train into a single DataFrame\n",
    "train_data = pd.concat([X, y_train], axis=1)\n",
    "\n",
    "# Separate the samples of each class\n",
    "class_0 = train_data[train_data['Exited'] == 0]\n",
    "class_1 = train_data[train_data['Exited'] == 1]\n",
    "\n",
    "# Resample the majority class (class_0) to match the number of samples in the minority class (class_1)\n",
    "class_0_resampled = resample(class_0, replace=True, n_samples=len(class_1), random_state=42)\n",
    "\n",
    "# Combine the resampled class_0 with the original class_1 to create a balanced dataset\n",
    "balanced_data = pd.concat([class_0_resampled, class_1])\n",
    "\n",
    "# Separate the features (X) and the target variable (y) from the balanced dataset\n",
    "X_balanced = balanced_data.drop('Exited', axis=1)\n",
    "y_balanced = balanced_data['Exited']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    1630\n",
       "1    1630\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)\n",
    "print(len(X_balanced))\n",
    "y_balanced.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned']\n",
    "continuous_features_engine = ['BalanceCredit', 'AgeProducts', 'SatisfactionProducts', 'CardProducts', 'TenurePoints']\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary', 'GenderBinary']\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "\n",
    "catboost_cls = CatBoostClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "    'classifier__depth': [6,7],\n",
    "}\n",
    "\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), continuous_features_engine),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_catboost_cls = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', catboost_cls)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_catboost_cls_hyper = GridSearchCV(pipe_catboost_cls, param_grid, scoring='f1_macro', n_jobs=-1, verbose=2, cv=2)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_catboost_cls_hyper.fit(X_balanced, y_balanced)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_catboost_cls_hyper.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_catboost_cls_hyper.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_catboost_cls_hyper.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_val_cluster)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "Best Parameters: {'classifier__learning_rate': 0.02, 'classifier__max_depth': 3, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 200, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.8}\n",
      "Best Score (F1 Macro): 0.7435654641714827\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       796\n",
      "           1       0.62      0.59      0.60       204\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.76      0.75      0.75      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'PointsEarned', 'TenurePoints', 'CardProducts', 'SatisfactionProducts', 'AgeProducts', 'BalanceCredit']\n",
    "\n",
    "categorical_features = ['HasCrCard', 'IsActiveMember', 'GenderBinary']\n",
    "\n",
    "cluster_features = ['ClusterKMeans', 'ClusterBGM']\n",
    "\n",
    "ordinal_features = ['Tenure', 'CardTypeOrd', 'NumOfProducts', 'NumOfProducts']\n",
    "\n",
    "target_enc_features = ['GenderBinary', 'CountryOrd', 'SurnameOrd', 'HasCrCard', 'IsActiveMember',  'Tenure', 'NumOfProducts','SatisfactionScore', 'TenurePoints', 'CardProducts', 'SatisfactionProducts', 'AgeProducts', 'BalanceCredit']\n",
    "\n",
    "\n",
    "# Create an instance of the XGBClassifier\n",
    "xgb_cls = XGBClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': [0.02],\n",
    "    'classifier__max_depth': [2, 3, 4],\n",
    "    'classifier__n_estimators': [200],\n",
    "    'classifier__reg_alpha': [0.5],\n",
    "    'classifier__min_child_weight': [1, 2, 3],\n",
    "    'classifier__subsample': [0.8],\n",
    "    'classifier__reg_lambda': [0.5],\n",
    "    'classifier__scale_pos_weight': [2]\n",
    "}\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_xgb_cls = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', xgb_cls)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_xg_hyper = GridSearchCV(pipe_xgb_cls, param_grid, cv=2, scoring='f1_macro', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_xg_hyper.fit(X , y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_xg_hyper.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_xg_hyper.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model_final_trans = grid_search_xg_hyper.best_estimator_\n",
    "\n",
    "y_pred = best_model_final_trans.predict(X_val_cluster)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
    "Best Parameters: {'classifier__learning_rate': 0.02, 'classifier__max_depth': 3, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 200, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.8}\n",
    "Best Score (F1 Macro): 0.7435654641714827\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.91      0.90       796\n",
    "           1       0.62      0.59      0.60       204\n",
    "\n",
    "    accuracy                           0.84      1000\n",
    "   macro avg       0.76      0.75      0.75      1000\n",
    "weighted avg       0.84      0.84      0.84      1000\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> \n",
    "Best hyperparameters i could find for X_train_cluster\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tenure</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>SatisfactionScore</th>\n",
       "      <th>CreditScoreOrd</th>\n",
       "      <th>AgeOrd</th>\n",
       "      <th>TaxBracket</th>\n",
       "      <th>BalanceOrd</th>\n",
       "      <th>PointsEarnedQuant</th>\n",
       "      <th>CardTypeOrd</th>\n",
       "      <th>SurnameOrd</th>\n",
       "      <th>CountryOrd</th>\n",
       "      <th>CountryHappy</th>\n",
       "      <th>GenderBinary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tenure  NumOfProducts  HasCrCard  IsActiveMember  SatisfactionScore  \\\n",
       "0       2              2          1               0                  2   \n",
       "1       1              1          1               1                  1   \n",
       "2       2              1          0               1                  1   \n",
       "3       4              1          1               0                  1   \n",
       "4       8              2          0               1                  3   \n",
       "\n",
       "   CreditScoreOrd  AgeOrd  TaxBracket  BalanceOrd  PointsEarnedQuant  \\\n",
       "0               3       1           4           0                1.0   \n",
       "1               4       1           3           1                2.0   \n",
       "2               4       4           4           3                2.0   \n",
       "3               2       1           1           2                0.0   \n",
       "4               3       3           3           0                2.0   \n",
       "\n",
       "   CardTypeOrd  SurnameOrd  CountryOrd  CountryHappy  GenderBinary  \n",
       "0          1.0         0.0           1          6.48             0  \n",
       "1          2.0         0.0           2          6.69             0  \n",
       "2          0.0         0.0           2          6.69             0  \n",
       "3          2.0         2.0           3          7.03             1  \n",
       "4          0.0         0.0           2          6.69             1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 9 candidates, totalling 63 fits\n",
      "Best Parameters: {'classifier__learning_rate': 0.02, 'classifier__max_depth': 4, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.8}\n",
      "Best Score (F1 Macro): 0.7556525898799006\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       796\n",
      "           1       0.64      0.57      0.60       204\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.76      0.74      0.75      1000\n",
      "weighted avg       0.84      0.85      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#* Let us look at the features without the ones created in the feature engineering notebook \n",
    "\n",
    "all_features = ['Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'SatisfactionScore',\n",
    "               'CreditScoreOrd', 'AgeOrd', 'TaxBracket', 'BalanceOrd', 'PointsEarnedQuant',\n",
    "               'CardTypeOrd', 'SurnameOrd', 'CountryOrd', 'GenderBinary']\n",
    "\n",
    "# Create an instance of the XGBClassifier\n",
    "xgb_cls = XGBClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': [0.02],\n",
    "    'classifier__max_depth': [2, 3, 4],\n",
    "    'classifier__n_estimators': [200],\n",
    "    'classifier__reg_alpha': [0.5],\n",
    "    'classifier__min_child_weight': [1, 2, 3],\n",
    "    'classifier__subsample': [0.8],\n",
    "    'classifier__reg_lambda': [0.5],\n",
    "    'classifier__scale_pos_weight': [2]\n",
    "}\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('all_features', 'passthrough', all_features)      \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_xgb_cls = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', xgb_cls)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_xg_hyper = GridSearchCV(pipe_xgb_cls, param_grid, cv=7, scoring='f1_macro', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_xg_hyper.fit(X_train , y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_xg_hyper.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_xg_hyper.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_xg_hyper.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "#* Again, no real difference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 7 folds for each of 9 candidates, totalling 63 fits\n",
    "Best Parameters: {'classifier__learning_rate': 0.02, 'classifier__max_depth': 4, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.8}\n",
    "Best Score (F1 Macro): 0.7556525898799006\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.92      0.90       796\n",
    "           1       0.64      0.57      0.60       204\n",
    "\n",
    "    accuracy                           0.85      1000\n",
    "   macro avg       0.76      0.74      0.75      1000\n",
    "weighted avg       0.84      0.85      0.84      1000\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 9 candidates, totalling 63 fits\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'classifier__learning_rate': 0.02, 'classifier__max_depth': 4, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.8}\n",
      "Best Score (F1 Macro): 0.7556525898799006\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       796\n",
      "           1       0.64      0.57      0.60       204\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.76      0.74      0.75      1000\n",
      "weighted avg       0.84      0.85      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#* Let us look at the features without the ones created in the feature engineering notebook \n",
    "\n",
    "all_features = ['Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'SatisfactionScore',\n",
    "               'CreditScoreOrd', 'AgeOrd', 'TaxBracket', 'BalanceOrd', 'PointsEarnedQuant',\n",
    "               'CardTypeOrd', 'SurnameOrd', 'CountryOrd', 'GenderBinary']\n",
    "\n",
    "# Create an instance of the XGBClassifier\n",
    "xgb_cls = XGBClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': [0.02],\n",
    "    'classifier__max_depth': [2, 3, 4],\n",
    "    'classifier__n_estimators': [200],\n",
    "    'classifier__reg_alpha': [0.5],\n",
    "    'classifier__min_child_weight': [1, 2, 3],\n",
    "    'classifier__subsample': [0.8],\n",
    "    'classifier__reg_lambda': [0.5],\n",
    "    'classifier__scale_pos_weight': [2]\n",
    "}\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), all_features),      \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_xgb_cls = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', xgb_cls)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_xg_hyper = GridSearchCV(pipe_xgb_cls, param_grid, cv=7, scoring='f1_macro', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_xg_hyper.fit(X_train , y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_xg_hyper.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_xg_hyper.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_xg_hyper.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "#* Again, no real difference.Target encoding seemed to have effect before"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 7 folds for each of 9 candidates, totalling 63 fits\n",
    "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
    "Best Parameters: {'classifier__learning_rate': 0.02, 'classifier__max_depth': 4, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.8}\n",
    "Best Score (F1 Macro): 0.7556525898799006\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.92      0.90       796\n",
    "           1       0.64      0.57      0.60       204\n",
    "\n",
    "    accuracy                           0.85      1000\n",
    "   macro avg       0.76      0.74      0.75      1000\n",
    "weighted avg       0.84      0.85      0.84      1000\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> \n",
    "Lastly, lets just try the original dataset, before we try predicting the test set \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Customer-Churn-Records.csv\")\n",
    "df = df.drop(columns=['RowNumber','CustomerId'])\n",
    "df = df.drop(columns=['Complain'])\n",
    "df = df.rename(columns={'Card Type': 'CardType'})\n",
    "df = df.rename(columns={'Point Earned': 'PointsEarned'})\n",
    "df = df.rename(columns={'Geography': 'Country'})\n",
    "df = df.rename(columns={'Satisfaction Score': 'SatisfactionScore'})\n",
    "# save original columns\n",
    "myColumns = df.columns\n",
    "y = df['Exited']\n",
    "df = df.drop(['Exited','Surname'], axis=1) # I drop Surname since we have not encoded it\n",
    "# yy = np.ravel(y)\n",
    "\n",
    "\n",
    "X_trainDF, X_tempDF, y_trainDF, y_tempDF = train_test_split(df, y, test_size=0.2, random_state=40)\n",
    "\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(df.drop('Exited', axis=1), df['Exited'], test_size=0.2, stratify=df['Exited'], random_state=42)\n",
    "\n",
    "# We use train_test_split twice so we can get a validation set as well\n",
    "X_valDF, X_testDF, y_valDF, y_testDF = train_test_split(X_tempDF, y_tempDF, test_size=0.5, stratify=y_tempDF, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 9 candidates, totalling 63 fits\n",
      "Best Parameters: {'classifier__learning_rate': 0.02, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.8}\n",
      "Best Score (F1 Macro): 0.7625244018295915\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       808\n",
      "           1       0.67      0.61      0.64       192\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.79      0.77      0.78      1000\n",
      "weighted avg       0.86      0.87      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# could benefit from scaling\n",
    "continuous_features = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'PointsEarned']\n",
    "# Need to be one hot encoded\n",
    "categorical_features = ['Country', 'Gender', 'CardType']\n",
    "# Are either in 0/1 boolean or is ordinal as default\n",
    "passthrough_features = ['Tenure', 'HasCrCard', 'IsActiveMember', 'SatisfactionScore','Tenure', 'NumOfProducts']\n",
    "\n",
    "\n",
    "xgb_cls = XGBClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': [0.02],\n",
    "    'classifier__max_depth': [2, 3, 4],\n",
    "    'classifier__n_estimators': [200],\n",
    "    'classifier__reg_alpha': [0.5],\n",
    "    'classifier__min_child_weight': [1, 2, 3],\n",
    "    'classifier__subsample': [0.8],\n",
    "    'classifier__reg_lambda': [0.5],\n",
    "    'classifier__scale_pos_weight': [2]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), categorical_features),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('passthrough', 'passthrough', passthrough_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipe_xg_cls_default = Pipeline([\n",
    "    ('preprocessor', prep),\n",
    "    ('classifier', xgb_cls)\n",
    "])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_xg_default = GridSearchCV(pipe_xg_cls_default, param_grid, scoring='f1_macro', n_jobs=-1, verbose=2, cv=7)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_xg_default.fit(X_trainDF, y_trainDF)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search_xg_default.best_params_)\n",
    "print(\"Best Score (F1 Macro):\", grid_search_xg_default.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model_default = grid_search_xg_default.best_estimator_\n",
    "\n",
    "y_pred = best_model_default.predict(X_valDF)\n",
    "\n",
    "report = classification_report(y_valDF, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "#* Wow, the original did better! So much work... Though this has different random rows compared to X_train & X_train_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "Fitting 7 folds for each of 9 candidates, totalling 63 fits\n",
    "Best Parameters: {'classifier__learning_rate': 0.02, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__reg_alpha': 0.5, 'classifier__reg_lambda': 0.5, 'classifier__scale_pos_weight': 2, 'classifier__subsample': 0.8}\n",
    "Best Score (F1 Macro): 0.7625244018295915\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.93      0.92       808\n",
    "           1       0.67      0.61      0.64       192\n",
    "\n",
    "    accuracy                           0.87      1000\n",
    "   macro avg       0.79      0.77      0.78      1000\n",
    "weighted avg       0.86      0.87      0.87      1000\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='LightBlue'> \n",
    "Now let us try the test set on both and save the model\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       796\n",
      "           1       0.66      0.65      0.65       204\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.78      0.78      0.78      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing the best model with the extensive feature engineering\n",
    "\n",
    "y_test = pd.read_csv(\"y_test_tran.csv\")\n",
    "\n",
    "y_pred = best_model_final_trans.predict(X_test_cluster)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.91      0.91       796\n",
    "           1       0.66      0.65      0.65       204\n",
    "\n",
    "    accuracy                           0.86      1000\n",
    "   macro avg       0.78      0.78      0.78      1000\n",
    "weighted avg       0.86      0.86      0.86      1000\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       808\n",
      "           1       0.65      0.61      0.63       192\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.78      0.77      0.77      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing the model with basic encoding only\n",
    "y_pred = best_model_default.predict(X_testDF)\n",
    "\n",
    "report = classification_report(y_testDF, y_pred)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Tangerine'> \n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.92      0.92       808\n",
    "           1       0.65      0.61      0.63       192\n",
    "\n",
    "    accuracy                           0.86      1000\n",
    "   macro avg       0.78      0.77      0.77      1000\n",
    "weighted avg       0.86      0.86      0.86      1000\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> \n",
    "In the end both models performed equally well\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline_trans_xgboost.joblib']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# save the pipeline\n",
    "dump(pipe_xgb_cls, 'pipeline_trans_xgboost.joblib')\n",
    "dump(pipe_xg_cls_default, 'pipeline_default_xgboost.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from joblib import load\n",
    "\n",
    "myPipe = load('pipeline_trans_xgboost.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;,\n",
       "                                                   &#x27;PointsEarned&#x27;,\n",
       "                                                   &#x27;TenurePoints&#x27;,\n",
       "                                                   &#x27;CardProducts&#x27;,\n",
       "                                                   &#x27;SatisfactionProducts&#x27;,\n",
       "                                                   &#x27;AgeProducts&#x27;,\n",
       "                                                   &#x27;BalanceCredit&#x27;]),\n",
       "                                                 (&#x27;ordinal&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;Tenure&#x27;, &#x27;CardTypeOrd&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;]),\n",
       "                                                 (&#x27;cluster&#x27;,...\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;,\n",
       "                                                   &#x27;PointsEarned&#x27;,\n",
       "                                                   &#x27;TenurePoints&#x27;,\n",
       "                                                   &#x27;CardProducts&#x27;,\n",
       "                                                   &#x27;SatisfactionProducts&#x27;,\n",
       "                                                   &#x27;AgeProducts&#x27;,\n",
       "                                                   &#x27;BalanceCredit&#x27;]),\n",
       "                                                 (&#x27;ordinal&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;Tenure&#x27;, &#x27;CardTypeOrd&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;]),\n",
       "                                                 (&#x27;cluster&#x27;,...\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Balance&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;, &#x27;EstimatedSalary&#x27;,\n",
       "                                  &#x27;PointsEarned&#x27;, &#x27;TenurePoints&#x27;,\n",
       "                                  &#x27;CardProducts&#x27;, &#x27;SatisfactionProducts&#x27;,\n",
       "                                  &#x27;AgeProducts&#x27;, &#x27;BalanceCredit&#x27;]),\n",
       "                                (&#x27;ordinal&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;Tenure&#x27;, &#x27;CardTypeOrd&#x27;, &#x27;NumOfProducts&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;]),\n",
       "                                (&#x27;cluster&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;ClusterKMeans&#x27;, &#x27;ClusterBGM&#x27;]),\n",
       "                                (&#x27;categorical&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;,\n",
       "                                  &#x27;GenderBinary&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;, &#x27;EstimatedSalary&#x27;, &#x27;PointsEarned&#x27;, &#x27;TenurePoints&#x27;, &#x27;CardProducts&#x27;, &#x27;SatisfactionProducts&#x27;, &#x27;AgeProducts&#x27;, &#x27;BalanceCredit&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Tenure&#x27;, &#x27;CardTypeOrd&#x27;, &#x27;NumOfProducts&#x27;, &#x27;NumOfProducts&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cluster</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ClusterKMeans&#x27;, &#x27;ClusterBGM&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;GenderBinary&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('scaler', StandardScaler(),\n",
       "                                                  ['CreditScore', 'Age',\n",
       "                                                   'Balance', 'NumOfProducts',\n",
       "                                                   'EstimatedSalary',\n",
       "                                                   'PointsEarned',\n",
       "                                                   'TenurePoints',\n",
       "                                                   'CardProducts',\n",
       "                                                   'SatisfactionProducts',\n",
       "                                                   'AgeProducts',\n",
       "                                                   'BalanceCredit']),\n",
       "                                                 ('ordinal', 'passthrough',\n",
       "                                                  ['Tenure', 'CardTypeOrd',\n",
       "                                                   'NumOfProducts',\n",
       "                                                   'NumOfProducts']),\n",
       "                                                 ('cluster',...\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myPipe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=''> \n",
    "Thank you for reading my notebooks!\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
