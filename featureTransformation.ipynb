{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Customer-Churn-Records.csv\")\n",
    "\n",
    "df = df.drop(columns=['RowNumber','CustomerId'])\n",
    "df = df.drop(columns=['Complain'])\n",
    "df = df.rename(columns={'Card Type': 'CardType'})\n",
    "df = df.rename(columns={'Point Earned': 'PointsEarned'})\n",
    "df = df.rename(columns={'Geography': 'Country'})\n",
    "df = df.rename(columns={'Satisfaction Score': 'SatisfactionScore'})\n",
    "myColumns = df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> \n",
    "We split the data now so that we dont draw conclusions from the whole dataset when transforming features. Since we want to simulate the real world occurrence of not having access to test data distribution.\n",
    "\n",
    "We also split the data into a validation and test set so that we later can fine tune on the validation set and not risk 'data leakage' (i think that is the right term).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 14)\n",
      "(8000,)\n",
      "(1000, 14)\n",
      "(1000,)\n",
      "(1000, 14)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#* Split the dataset so that we fit_transform the training data and transform the test data\n",
    "\n",
    "# since the target feature is a bit uneven we stratify so that it does not effect us to much at this stage\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df.drop('Exited', axis=1), df['Exited'], test_size=0.2, stratify=df['Exited'], random_state=42)\n",
    "\n",
    "# We use train_test_split twice so we can get a validation set as well\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "# It is worth considering to use train_test_split again to get a holdout set.\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>SatisfactionScore</th>\n",
       "      <th>CardType</th>\n",
       "      <th>PointsEarned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor</td>\n",
       "      <td>709</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104982.39</td>\n",
       "      <td>2</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kornilova</td>\n",
       "      <td>744</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>43504.42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119327.75</td>\n",
       "      <td>1</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kodilinyechukwu</td>\n",
       "      <td>773</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>145578.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>186172.85</td>\n",
       "      <td>1</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wang</td>\n",
       "      <td>646</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>105957.44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15470.91</td>\n",
       "      <td>1</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baresi</td>\n",
       "      <td>675</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95463.29</td>\n",
       "      <td>3</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Surname  CreditScore  Country  Gender  Age  Tenure    Balance  \\\n",
       "0           Taylor          709    Spain    Male   35       2       0.00   \n",
       "1        Kornilova          744   France    Male   29       1   43504.42   \n",
       "2  Kodilinyechukwu          773   France    Male   64       2  145578.28   \n",
       "3             Wang          646  Germany  Female   29       4  105957.44   \n",
       "4           Baresi          675   France  Female   57       8       0.00   \n",
       "\n",
       "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0              2          1               0        104982.39   \n",
       "1              1          1               1        119327.75   \n",
       "2              1          0               1        186172.85   \n",
       "3              1          1               0         15470.91   \n",
       "4              2          0               1         95463.29   \n",
       "\n",
       "   SatisfactionScore  CardType  PointsEarned  \n",
       "0                  2      GOLD           422  \n",
       "1                  1  PLATINUM           607  \n",
       "2                  1    SILVER           630  \n",
       "3                  1  PLATINUM           345  \n",
       "4                  3    SILVER           632  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='0FF00'> \n",
    "Let us feature transform each feature now! \n",
    "There are several different encodings and transformations we could try.\n",
    "Some of them, such as target encoding, are more experimental in nature.\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'>\"Banks usually categorize credit scores into several risk profiles or categories. According to CNBC 1, credit scores are typically divided into five categories:\n",
    "\n",
    "Deep subprime: Credit scores below 580\n",
    "Subprime: Credit scores between 580 and 619\n",
    "Near-prime: Credit scores between 620 and 659\n",
    "Prime: Credit scores between 660 and 719\n",
    "Super-prime: Credit scores of 720 or above\n",
    "\n",
    "These categories help banks assess the creditworthiness of borrowers and determine the types of financial products and interest rates they are eligible for\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#! CreditScore\n",
    "\n",
    "# Create a dictionary mapping credit score ranges to ordinal values\n",
    "encoding_dict = {\n",
    "    (0, 580): 0,\n",
    "    (581, 619): 1,\n",
    "    (620, 659): 2,\n",
    "    (660, 719): 3,\n",
    "    (720, 10000): 4\n",
    "}\n",
    "\n",
    "# Define a function to apply the ordinal encoding\n",
    "def apply_encoding(credit_score):\n",
    "    for score_range, encoded_value in encoding_dict.items():\n",
    "        if score_range[0] <= credit_score <= score_range[1]:\n",
    "            return encoded_value\n",
    "\n",
    "# Apply ordinal encoding using apply() function\n",
    "X_train['CreditScoreOrd'] = X_train['CreditScore'].apply(apply_encoding)\n",
    "X_test['CreditScoreOrd'] = X_test['CreditScore'].apply(apply_encoding)\n",
    "X_val['CreditScoreOrd'] = X_val['CreditScore'].apply(apply_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Age\n",
    "\n",
    "#* Only difference is that the countries have different retirement ages.\n",
    "#* I also considered binning the age where students start university.\n",
    "age_groups = {\n",
    "    'France': [(18, 24), (25, 35), (36, 45), (46, 62), (63 , 100)],\n",
    "    'Germany': [(18, 24), (25, 35), (36, 45), (46, 65), (66 , 100)], \n",
    "    'Spain': [(18, 24), (25, 35), (36, 45), (46, 66), (67 , 100)],\n",
    "}\n",
    "\n",
    "#? https://www.thelocal.de/20230127/how-does-germanys-retirement-age-compare-to-the-rest-of-europe\n",
    "#? https://www.cleiss.fr/docs/regimes/regime_france/an_3.html\n",
    "#? https://www.caserexpatinsurance.com/blog-typical-non-spanish/retirement-age-in-spain\n",
    "\n",
    "def get_age_groups(country, age):\n",
    "    tax_ranges = age_groups[country]\n",
    "    for index, tax_range in enumerate(tax_ranges):\n",
    "        if tax_range[0] <= age <= tax_range[1]:\n",
    "            return index\n",
    "    return None\n",
    "\n",
    "X_train['AgeOrd'] = X_train.apply(lambda row: get_age_groups(row['Country'], row['Age']), axis=1)\n",
    "X_test['AgeOrd'] = X_test.apply(lambda row: get_age_groups(row['Country'], row['Age']), axis=1)\n",
    "X_val['AgeOrd'] = X_val.apply(lambda row: get_age_groups(row['Country'], row['Age']), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'> \n",
    "I discretize EstimatedSalary salary based on tax brackets that are used in the respective country of the member.\n",
    "\n",
    "Spain has one more bracket compared to France and Germany, so there are multiple ways to handle this. I just merged the top brackets.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#! EstimatedSalary\n",
    "\n",
    "tax_brackets = {\n",
    "    'France': [(0, 10_225), (10_226, 26_070), (26_071, 74_545), (74_546, 160_336), (16_0337, float('inf'))], # For 2022\n",
    "    'Germany': [(0, 10_347), (10_348, 15_999), (16000, 62809), (62810, 277825), (277826, float('inf'))], # For 2023. Also the source has a gap between the first brackets that i filled in (Up to 10,347. 10,909-15,999)\n",
    "    'Spain': [(0, 12_450), (12451, 20200), (20201, 35200), (35201, 100000), (100001, float('inf'))], # For 2021. Spain has 6 brackets, so we are combining the highest 2\n",
    "}\n",
    "\n",
    "def get_tax_bracket(country, salary):\n",
    "    tax_ranges = tax_brackets[country]\n",
    "    for index, tax_range in enumerate(tax_ranges):\n",
    "        if tax_range[0] <= salary <= tax_range[1]:\n",
    "            return index\n",
    "    return None\n",
    "\n",
    "X_train['TaxBracket'] = X_train.apply(lambda row: get_tax_bracket(row['Country'], row['EstimatedSalary']), axis=1)\n",
    "X_test['TaxBracket'] = X_test.apply(lambda row: get_tax_bracket(row['Country'], row['EstimatedSalary']), axis=1)\n",
    "X_val['TaxBracket'] = X_val.apply(lambda row: get_tax_bracket(row['Country'], row['EstimatedSalary']), axis=1)\n",
    "\n",
    "\n",
    "#? https://www.worldwide-tax.com/france/france-taxes.asp\n",
    "#? https://www.worldwide-tax.com/spain/spain-taxes.asp\n",
    "#? https://www.worldwide-tax.com/germany/germany-taxes.asp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'> \n",
    "The important thing with Balance is that zero balance gets its own category, since its probable that it correlates uniquely with other features. Does not have to mean that the customer has little money, perhaps they are not using the bank to save any money at all\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#! Balance\n",
    "#* I grouped according to the distribution (so that the split between 50% is between group 3 and 4)\n",
    "encoding_dict = {\n",
    "    (-1, 1): 0,\n",
    "    (2, 100_000): 1,\n",
    "    (100_001, 125_000): 2,\n",
    "    (125_001, 149_999): 3,\n",
    "    (150_000, 300_000): 4\n",
    "}\n",
    "\n",
    "# Define a function to apply the ordinal encoding\n",
    "def apply_encoding(balance):\n",
    "    for balance_range, encoded_value in encoding_dict.items():\n",
    "        if balance_range[0] <= balance <= balance_range[1]:\n",
    "            return encoded_value\n",
    "\n",
    "# Apply ordinal encoding using apply() function\n",
    "X_train['BalanceOrd'] = X_train['Balance'].apply(apply_encoding)\n",
    "X_test['BalanceOrd'] = X_test['Balance'].apply(apply_encoding)\n",
    "X_val['BalanceOrd'] = X_val['Balance'].apply(apply_encoding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'> \n",
    "Have not found anything that points earned correlates with any other feature\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#! PointsEarned\n",
    "#* I decided to bin PointsEarned using the quntiles\n",
    "\n",
    "PointsEarnedValues = X_train['PointsEarned'].values.reshape(-1, 1)\n",
    "PointsEarnedValues_test = X_test['PointsEarned'].values.reshape(-1, 1)\n",
    "PointsEarnedValues_val = X_val['PointsEarned'].values.reshape(-1, 1)\n",
    "\n",
    "# Create a KBinsDiscretizer object with 5 bins and the quantile strategy\n",
    "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "\n",
    "# Fit and transform the data using the discretizer\n",
    "#* I make sure to fit on the val and test sets and only transform\n",
    "PointsEarnedEnc = discretizer.fit_transform(PointsEarnedValues)\n",
    "PointsEarnedEnc_test = discretizer.transform(PointsEarnedValues_test)\n",
    "PointsEarnedEnc_val = discretizer.transform(PointsEarnedValues_val)\n",
    "\n",
    "# Assign the discretized values to a new column in the DataFrame\n",
    "X_train['PointsEarnedQuant'] = PointsEarnedEnc.flatten()\n",
    "X_test['PointsEarnedQuant'] = PointsEarnedEnc_test.flatten()\n",
    "X_val['PointsEarnedQuant'] = PointsEarnedEnc_val.flatten()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'> \n",
    "Let us do the same with credit card\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#! CardType Credit card type\n",
    "\n",
    "# Ordinal encoding based on cardType value level makes sense\n",
    "CardTypeValues = X_train['CardType'].values.reshape(-1, 1)\n",
    "CardTypeValues_test = X_test['CardType'].values.reshape(-1, 1)\n",
    "CardTypeValues_val = X_val['CardType'].values.reshape(-1, 1)\n",
    "\n",
    "# Define the order of the cards as a list\n",
    "card_order = ['SILVER', 'GOLD', 'PLATINUM', 'DIAMOND']\n",
    "\n",
    "# Create an OrdinalEncoder object with the desired order\n",
    "encoder = OrdinalEncoder(categories=[card_order])\n",
    "\n",
    "# Fit and transform the data using the encoder\n",
    "#! this is not necessary since we are not fitting a distribution\n",
    "CardTypeEnc = encoder.fit_transform(CardTypeValues)\n",
    "CardTypeEnc_test = encoder.transform(CardTypeValues_test)\n",
    "CardTypeEnc_val = encoder.transform(CardTypeValues_val)\n",
    "\n",
    "# Assign the encoded values to a new column in the DataFrame\n",
    "X_train['CardTypeOrd'] = CardTypeEnc.flatten()\n",
    "X_test['CardTypeOrd'] = CardTypeEnc_test.flatten()\n",
    "X_val['CardTypeOrd'] = CardTypeEnc_val.flatten()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'> \n",
    "Even though we did not find a significant correlation between name count and Exited we will try frequency encoding, since there could be some more complex relationships that the models could uncover\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#* Ordinal encoding of Surname based on name count (only the 10 most common names), less common names get encoded as 0\n",
    "\n",
    "# Calculate the frequency of occurrence for each value in the 'Surname' column\n",
    "value_frequencies = X_train['Surname'].value_counts()\n",
    "\n",
    "# Select the top 11 most common names\n",
    "top_names = value_frequencies.nlargest(11).index\n",
    "\n",
    "# Reverse index so that most common name gets encoded as the highest value\n",
    "top_names = top_names[::-1]\n",
    "\n",
    "# Create a dictionary mapping the top names to their ordinal values (0 to 9)\n",
    "encoding_dict = {name: i for i, name in enumerate(top_names)}\n",
    "\n",
    "# Use the dictionary to map the 'Surname' column values to their ordinal values in a new column,\n",
    "# assigning 0 to the remaining names\n",
    "\n",
    "X_train['SurnameOrd'] = X_train['Surname'].map(encoding_dict).fillna(0)\n",
    "X_test['SurnameOrd'] = X_test['Surname'].map(encoding_dict).fillna(0)\n",
    "X_val['SurnameOrd'] = X_val['Surname'].map(encoding_dict).fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'> Purchasing power parities (PPPs) are the rates of currency conversion that try to equalise the purchasing power of different currencies, by eliminating the differences in price levels between countries. The basket of goods and services priced is a sample of all those that are part of final expenditures: final consumption of households and government, fixed capital formation, and net exports. This indicator is measured in terms of national currency per US dollar.   </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#* Let us try to ordinal encode country based on PPP.\n",
    "countryPPP = {'Germany': 0.913, 'Spain':0.742, 'France': 0.901}\n",
    "#* Let us just get the order from this rather than teh PPP value\n",
    "countryPPP = {'Germany': 3, 'Spain':1, 'France': 2}\n",
    "#! Could be a bad idea since we are pretty sure that Germans are leaving the bank the most.\n",
    "\n",
    "X_train['CountryOrd'] = X_train['Country'].map(countryPPP)\n",
    "X_test['CountryOrd'] = X_test['Country'].map(countryPPP)\n",
    "X_val['CountryOrd'] = X_val['Country'].map(countryPPP)\n",
    "\n",
    "\n",
    "#? https://data.oecd.org/conversion/purchasing-power-parities-ppp.htm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'> \n",
    "While we are at it. Le us try to add some wellbeing scores for each country since happiness is highly correalted with your economy (more on the lower end though)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#* Let us try to ordinal encode country based on PPP.\n",
    "countryHappyScore = {'Germany': 7.03, 'Spain':6.48, 'France': 6.69}\n",
    "#* Let us just get the order from this rather than teh PPP value\n",
    "countryHappyScoreOrd = {'Germany': 3, 'Spain':1, 'France': 2}\n",
    "\n",
    "X_train['CountryHappy'] = X_train['Country'].map(countryHappyScore)\n",
    "X_test['CountryHappy'] = X_test['Country'].map(countryHappyScore)\n",
    "X_val['CountryHappy'] = X_val['Country'].map(countryHappyScore)\n",
    "\n",
    "#! Since the countries will get the same ordinal scores as they did with the PPP encoding it will not be able to uncover any none-linear patterns. So we either encode a different way (e.g. proportional or keep the happy number) or dont add this feature it all\n",
    "\n",
    "#? https://wisevoter.com/country-rankings/happiest-countries-in-the-world/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#* Gender is the only binary feature that is in string format\n",
    "X_train['GenderBinary'] = X_train['Gender'].apply(lambda x: 0 if x == 'Male' else 1)\n",
    "X_test['GenderBinary'] = X_test['Gender'].apply(lambda x: 0 if x == 'Male' else 1)\n",
    "X_val['GenderBinary'] = X_val['Gender'].apply(lambda x: 0 if x == 'Male' else 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'> \n",
    "Tenure and NumofProducts are ordinal by default so no need to transorm (to clarify you dont need to ordinal encode since, usually one-hot is good option)\n",
    "\n",
    "HasCrCard, IsActiveMember, Complain are already label encoded (which is also one-hot in this case). Also our target feature Exited does also not need a transformation.\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='skyBlue'> \n",
    "Let us end this stage by dropping the features that have been transformed\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#* We are dropping every feature that has been transformed. The features that dont need transformation are kept\n",
    "X_train = X_train.drop(['Surname', 'CreditScore', 'Country', 'Age', 'Balance', 'EstimatedSalary', 'CardType', 'PointsEarned', 'Gender'], axis=1)\n",
    "X_test = X_test.drop(['Surname', 'CreditScore', 'Country', 'Age', 'Balance', 'EstimatedSalary', 'CardType', 'PointsEarned', 'Gender'], axis=1)\n",
    "X_val = X_val.drop(['Surname', 'CreditScore', 'Country', 'Age', 'Balance', 'EstimatedSalary', 'CardType', 'PointsEarned', 'Gender'], axis=1)\n",
    "\n",
    "# reset index\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "\n",
    "#* saving the transformed dataFrame\n",
    "X_train.to_csv('X_train_tran.csv', index=False)\n",
    "X_test.to_csv('X_test_tran.csv', index=False)\n",
    "y_train.to_csv('y_train_tran.csv', index=False)\n",
    "y_test.to_csv('y_test_tran.csv', index=False)\n",
    "X_val.to_csv('X_val_tran.csv', index=False)\n",
    "y_val.to_csv('y_val_tran.csv', index=False)\n",
    "#* The y_test and y_train has not really been transformed but i decided to group them based on name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tenure</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>SatisfactionScore</th>\n",
       "      <th>CreditScoreOrd</th>\n",
       "      <th>AgeOrd</th>\n",
       "      <th>TaxBracket</th>\n",
       "      <th>BalanceOrd</th>\n",
       "      <th>PointsEarnedQuant</th>\n",
       "      <th>CardTypeOrd</th>\n",
       "      <th>SurnameOrd</th>\n",
       "      <th>CountryOrd</th>\n",
       "      <th>CountryHappy</th>\n",
       "      <th>GenderBinary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tenure  NumOfProducts  HasCrCard  IsActiveMember  SatisfactionScore  \\\n",
       "0        2              2          1               0                  2   \n",
       "1        1              1          1               1                  1   \n",
       "2        2              1          0               1                  1   \n",
       "3        4              1          1               0                  1   \n",
       "4        8              2          0               1                  3   \n",
       "5       10              1          1               0                  1   \n",
       "6        2              1          1               1                  3   \n",
       "7        1              1          1               1                  3   \n",
       "8        1              2          0               0                  2   \n",
       "9        6              2          1               1                  1   \n",
       "10       8              2          0               1                  1   \n",
       "11       8              2          1               1                  1   \n",
       "12       0              1          0               0                  2   \n",
       "13       5              1          0               1                  5   \n",
       "14       0              1          0               0                  1   \n",
       "15       6              2          0               1                  1   \n",
       "16       8              1          0               0                  4   \n",
       "17       9              1          1               1                  5   \n",
       "18       9              1          1               0                  3   \n",
       "19       8              1          0               1                  3   \n",
       "\n",
       "    CreditScoreOrd  AgeOrd  TaxBracket  BalanceOrd  PointsEarnedQuant  \\\n",
       "0                3       1           4           0                1.0   \n",
       "1                4       1           3           1                2.0   \n",
       "2                4       4           4           3                2.0   \n",
       "3                2       1           1           2                0.0   \n",
       "4                3       3           3           0                2.0   \n",
       "5                4       3           3           1                3.0   \n",
       "6                0       1           3           3                1.0   \n",
       "7                3       3           3           1                4.0   \n",
       "8                0       2           3           4                0.0   \n",
       "9                2       1           3           0                3.0   \n",
       "10               3       2           4           0                4.0   \n",
       "11               0       3           3           3                4.0   \n",
       "12               4       0           2           1                1.0   \n",
       "13               0       3           3           1                0.0   \n",
       "14               2       2           2           3                0.0   \n",
       "15               2       2           3           1                1.0   \n",
       "16               4       2           4           2                3.0   \n",
       "17               3       2           3           2                4.0   \n",
       "18               1       1           2           1                2.0   \n",
       "19               0       2           1           3                0.0   \n",
       "\n",
       "    CardTypeOrd  SurnameOrd  CountryOrd  CountryHappy  GenderBinary  \n",
       "0           1.0         0.0           1          6.48             0  \n",
       "1           2.0         0.0           2          6.69             0  \n",
       "2           0.0         0.0           2          6.69             0  \n",
       "3           2.0         2.0           3          7.03             1  \n",
       "4           0.0         0.0           2          6.69             1  \n",
       "5           2.0         0.0           3          7.03             0  \n",
       "6           2.0         0.0           3          7.03             0  \n",
       "7           2.0         0.0           3          7.03             0  \n",
       "8           0.0         0.0           2          6.69             1  \n",
       "9           2.0         0.0           1          6.48             1  \n",
       "10          2.0         0.0           2          6.69             1  \n",
       "11          2.0         0.0           3          7.03             0  \n",
       "12          2.0         0.0           3          7.03             0  \n",
       "13          0.0         0.0           3          7.03             1  \n",
       "14          0.0         0.0           2          6.69             0  \n",
       "15          0.0         0.0           3          7.03             0  \n",
       "16          1.0         0.0           1          6.48             1  \n",
       "17          1.0         0.0           3          7.03             0  \n",
       "18          1.0         0.0           2          6.69             0  \n",
       "19          2.0         0.0           2          6.69             1  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
       "       'SatisfactionScore', 'CreditScoreOrd', 'AgeOrd', 'TaxBracket',\n",
       "       'BalanceOrd', 'PointsEarnedQuant', 'CardTypeOrd', 'SurnameOrd',\n",
       "       'CountryOrd', 'CountryHappy', 'GenderBinary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
